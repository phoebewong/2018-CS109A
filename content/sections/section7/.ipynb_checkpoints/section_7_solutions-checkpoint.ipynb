{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Standard Section 7: Discriminant Analysis and Decision Trees\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Section Leaders:** Mehul Smriti Raje, Ken Arnold, Karan Motwani, Cecilia Garraffo<br/>\n",
    "**Instructors:** Pavlos Protopapas, Kevin Rader <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This data is from the Sloan Digital Sky Server (http://cas.sdss.org/dr14/en/sdss/sdsshome.aspx)\n",
    "\n",
    "#### The Sloan Digital Sky Survey ia a project to make a map of a large part of the universe using a 2.5 meters telescope located at Apache Point Observatory in New Mexico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f46dad7316e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sdss.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image('data/sdss.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image from SDSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few physics concepts for this section:\n",
    "\n",
    "### 1) Blackbody Radiation:\n",
    "\n",
    "\n",
    "#### All objects with a temperature above absolute zero (0 K, -273.15 oC) emit energy in the form of electromagnetic radiation.  A blackbody is a theoretical or model body which absorbs all radiation falling on it, reflecting or transmitting none. It is a hypothetical object which is a “perfect” absorber and a “perfect” emitter of radiation over all wavelengths.  The spectral distribution of the thermal energy radiated by a blackbody (i.e. the pattern of the intensity of the radiation over a range of wavelengths or frequencies) depends only on its temperature.\n",
    "\n",
    "#### Based on this concept, astronomers use the distibution of measured colors in an object as a proxy for its temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('data/blackbody_radn_curves.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image & text from Swinburne University of Technology (http://astronomy.swin.edu.au/cosmos/B/Blackbody+Radiation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Redshift:\n",
    "\n",
    "#### Doppler effect can be described by the change in wavelength of light emitted by moving source.  A receding object emits light systematically moved towards larger wavelengths (to the red colors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('data/redshift.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because the universe is expanding, objects further from us will reced faster (think of a balloon being inflated and how the relative velocity of two points further away on its surface will be larger than that of two nearby points). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('data/expansion.jpeg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image from Quora (https://www.quora.com/If-the-age-of-universe-is-14-billion-years-how-are-we-able-to-receive-signals-from-galaxies-300-billion-light-years-away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining these two concepts it is possible to estimate the distance of a body based on the energy distribution of its emission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Quasar:\n",
    "\n",
    "#### Quasars are the most luminous objects in our Universe, some of them thousands of times brighter than our galaxy. They are located at the center of some galaxies and, while they are black holes, they emit light because they are accreating very hot plasma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('data/quasar.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Image from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky = pd.read_csv('data/Skyserver_2.csv')\n",
    "display(sky.head())\n",
    "display(sky.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single-letter columns are the spectral energy in certain bands of wavelengths, so the differences between them tell us about color. Astronomers typically look at the following differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky['u-g'] = sky['u'] - sky['g']\n",
    "sky['g-r'] = sky['g'] - sky['r']\n",
    "sky['r-i'] = sky['r'] - sky['i']\n",
    "sky.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check\n",
    "\n",
    "max(abs((sky['u']-sky['r'])-(sky['u-g']+ sky['g-r'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QSO is Quasars, representing about 10% of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to represent our target classes numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name2idx = ['GALAXY', 'STAR', 'QSO']\n",
    "class_idx2name = {name: idx for idx, name in enumerate(class_name2idx)}\n",
    "display(class_idx2name)\n",
    "sky['response'] = [class_idx2name[cls] for cls in sky['class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redshift makes much more sense in log-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky['log_redshift'] = np.log(np.maximum(sky.redshift, 0) + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_raw, data_test_raw = train_test_split(sky, test_size=.3, random_state=2001)\n",
    "len(data_train_raw), len(data_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_raw.groupby('class').log_redshift.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, means, stds):\n",
    "    cols_to_scale = means.index\n",
    "    df = df.copy()\n",
    "    df[cols_to_scale] = (df[cols_to_scale] - means) / stds\n",
    "    return df\n",
    "\n",
    "cols_to_scale = ['u-g', 'g-r', 'r-i']\n",
    "train_means = data_train_raw[cols_to_scale].mean(axis=0)\n",
    "train_stds = data_train_raw[cols_to_scale].std(axis=0)\n",
    "\n",
    "data_train = scale_df(data_train_raw, train_means, train_stds)\n",
    "data_test = scale_df(data_test_raw, train_means, train_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results.\n",
    "data_train[cols_to_scale].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_stars(ax, df, columns, class_labels, class_colors, s=5,\n",
    "                  xlim=[-4, 4], ylim=[-4, 4], **kw):\n",
    "    for idx, (color, name) in enumerate(zip(class_colors, class_labels)):\n",
    "        subset = df[df['class'] == name]\n",
    "        ax.scatter(\n",
    "            subset[columns[0]], subset[columns[1]],\n",
    "            label=name,\n",
    "            c=color, s=s, **kw)\n",
    "    ax.set(xlabel=columns[0], ylabel=columns[1], xlim=xlim, ylim=ylim)\n",
    "    ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "scatter_stars(\n",
    "    ax, data_train.sample(frac=.05),\n",
    "    columns=['u-g', 'g-r'],\n",
    "    class_labels=class_idx2name,\n",
    "    class_colors=['r', 'g', 'b'], s=1, alpha=.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: the overplotting between Star and Galaxy is deceptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(sky[columns[0]], sky[columns[1]], c=np.array(colors)[sky['response']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['u-g', 'g-r']\n",
    "\n",
    "X_train = data_train.loc[:,predictors]\n",
    "y_train = data_train.loc[:,'response']\n",
    "X_test = data_test.loc[:,predictors]\n",
    "y_test = data_test.loc[:,'response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One v. Rest\n",
    "lrm_ovr = LogisticRegressionCV(multi_class = 'ovr', cv=5)\n",
    "\n",
    "t = time.time()\n",
    "lrm_ovr.fit(X_train, y_train)\n",
    "runtime_ovr = time.time()-t\n",
    "\n",
    "#Multinomial - according to the documentation, the liblinear solver doesn't work for multinomial\n",
    "lrm_multinomial = LogisticRegressionCV(multi_class='multinomial', solver = 'saga')\n",
    "t = time.time()\n",
    "lrm_multinomial.fit(X_train, y_train)\n",
    "runtime_multi = time.time()-t\n",
    "\n",
    "\n",
    "print('OVR Logistic Regression Test Score: ',lrm_ovr.score(X_test, y_test), ', runtime: ', runtime_ovr)\n",
    "print('Multinomial Logistic Regression Test Score: ',lrm_multinomial.score(X_test, y_test), ', runtime: ', runtime_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals = [10, 50, 100]\n",
    "t = time.time()\n",
    "knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    {'n_neighbors': kvals}).fit(X_train, y_train)\n",
    "runtime_knn = time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best k:\", knn.best_params_['n_neighbors'])\n",
    "print('kNN Test Score:', knn.score(X_test, y_test), ', runtime= ', runtime_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kvals, knn.cv_results_['mean_test_score'], '-*')\n",
    "plt.fill_between(\n",
    "    kvals,\n",
    "    knn.cv_results_['mean_test_score'] - 2 * knn.cv_results_['std_test_score'],\n",
    "    knn.cv_results_['mean_test_score'] + 2 * knn.cv_results_['std_test_score'],\n",
    "    alpha=.3)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('validation accuracy +- 2 std');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(store_covariance=True, priors=[1,1,1])\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True, priors=[1,1,1])\n",
    "t = time.time()\n",
    "lda.fit(X_train, y_train)\n",
    "runtime_lda = time.time()-t\n",
    "\n",
    "t = time.time()\n",
    "qda.fit(X_train, y_train)\n",
    "runtime_qda = time.time()-t\n",
    "\n",
    "print('LDA Test Score: ',lda.score(X_test, y_test), ' runtime: ', runtime_lda)\n",
    "print('QDA Test Score: ',qda.score(X_test, y_test), ' runtime: ', runtime_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code credit: sklearn example\n",
    "def plot_confusion_matrix(ax, cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "    img = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar(img, ax=ax)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set(xticks=tick_marks, yticks=tick_marks)\n",
    "    ax.set_xticklabels(classes, rotation=45)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.set(title=title, ylabel='True label', xlabel='Predicted label')\n",
    "    \n",
    "# Alt:\n",
    "# sns.heatmap(\n",
    "#     cnf_matrix / cnf_matrix.sum(axis=1, keepdims=True),\n",
    "#     xticklabels=class_name2idx, yticklabels=class_name2idx,\n",
    "#     cmap=plt.cm.Blues, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(16,8))\n",
    "for ax, title, model in zip(axs, 'LDA QDA'.split(), [lda, qda]):\n",
    "    cnf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "#     cnf_matrix = confusion_matrix(np.full_like(y_test, 2), y_test)\n",
    "    plot_confusion_matrix(ax, cnf_matrix, classes=class_name2idx, normalize=True)\n",
    "    ax.set_title(title)\n",
    "#plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_decision_boundary(ax, model, colors=None, nx=200, ny=200, desaturate=.5):\n",
    "    \"\"\"\n",
    "    A function that visualizes the decision boundaries of a classifier.\n",
    "    \n",
    "    ax: Matplotlib Axes to plot on\n",
    "    model: Classifier (has a `.predict` method)\n",
    "    X: feature vectors\n",
    "    y: ground-truth classes\n",
    "    colors: list of colors to use. Use color colors[i] for class i.\n",
    "    nx, ny: number of mesh points to evaluated the classifier on\n",
    "    desaturate: how much to desaturate each of the colors (for better contrast with the sample points)\n",
    "    \"\"\"\n",
    "    # Create mesh\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(xmin, xmax, nx),\n",
    "        np.linspace(ymin, ymax, ny))\n",
    "    X = np.c_[xx.flatten(), yy.flatten()]\n",
    "\n",
    "    # Predict on mesh of points\n",
    "    model = getattr(model, 'predict', model)\n",
    "    y = model(X)\n",
    "    y = y.reshape((nx, ny))\n",
    "\n",
    "    # Generate colormap.\n",
    "    if colors is None:\n",
    "        colors = sns.utils.get_color_cycle()\n",
    "        y -= y.min() # If first class is not 0, shift.\n",
    "    assert np.max(y) <= len(colors)\n",
    "    colors = [sns.utils.desaturate(color, desaturate) for color in colors]\n",
    "    cmap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "    # Plot decision surface\n",
    "    ax.pcolormesh(xx, yy, y, zorder=-2, cmap=cmap, norm=matplotlib.colors.NoNorm(), vmin=0, vmax=y.max() + 1)\n",
    "    xx = xx.reshape(nx, ny)\n",
    "    yy = yy.reshape(nx, ny)\n",
    "#     ax.contourf(xx, yy, y, cmap=cmap, vmin=0, vmax=3)\n",
    "    ax.contour(xx, yy, y, colors=\"black\", linewidths=1, zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy_score(y_true, y_pred):\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        per_class = np.diag(C) / C.sum(axis=1)\n",
    "    if np.any(np.isnan(per_class)):\n",
    "        warnings.warn('y_pred contains classes not in y_true')\n",
    "        per_class = per_class[~np.isnan(per_class)]\n",
    "    score = np.mean(per_class)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = [lda, qda]\n",
    "titles = ['LDA','QDA']\n",
    "class_colors=['r', 'g', 'b']\n",
    "\n",
    "f, axes = plt.subplots(1,2, figsize = (16,7))\n",
    "data_sample = data_train.sample(frac=.05)\n",
    "\n",
    "for i, (model, ax, title) in enumerate(zip(fitted_models, axes, titles)):\n",
    "    scatter_stars(\n",
    "        ax, data_sample,\n",
    "        columns=['u-g', 'g-r'],\n",
    "        class_labels=class_idx2name, class_colors=class_colors, edgecolor='black', lw=.25, s=10)\n",
    "\n",
    "    overlay_decision_boundary(ax, model, colors=class_colors, desaturate=.3)\n",
    "    ax.set_title(title)\n",
    "    print(\"{}: accuracy on train={:.2%}, test={:.2%}\".format(\n",
    "        title, balanced_accuracy_score(y_train, model.predict(X_train)),\n",
    "        balanced_accuracy_score(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code credit: http://scikit-learn.org/stable/auto_examples/classification/plot_lda_qda.html\n",
    "def plot_ellipse(ax, mean, cov, color):\n",
    "    v, w = np.linalg.eigh(cov)\n",
    "    u = w[0] / np.linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    # filled Gaussian at 2 standard deviation\n",
    "    ell = matplotlib.patches.Ellipse(mean, 2 * v[0] ** 0.5, 2 * v[1] ** 0.5,\n",
    "                              180 + angle, facecolor=color,\n",
    "                              edgecolor='yellow',\n",
    "                              linewidth=2, zorder=2)\n",
    "    ell.set_clip_box(ax.bbox)\n",
    "    ell.set_alpha(0.5)\n",
    "    ax.add_artist(ell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = [lda, qda]\n",
    "titles = ['LDA','QDA']\n",
    "class_colors=['r', 'g', 'b']\n",
    "\n",
    "f, axes = plt.subplots(1,2, figsize = (16,7))\n",
    "data_sample = data_train.sample(frac=.05)\n",
    "\n",
    "for i, (model, ax, title) in enumerate(zip(fitted_models, axes, titles)):\n",
    "    scatter_stars(\n",
    "        ax, data_sample,\n",
    "        columns=['u-g', 'g-r'],\n",
    "        class_labels=class_idx2name, class_colors=class_colors, edgecolor='black', lw=.5, s=10)\n",
    "    for target, color in enumerate(class_colors):\n",
    "        if isinstance(model, QuadraticDiscriminantAnalysis):\n",
    "            # For QDA\n",
    "            covariance = model.covariance_[target]\n",
    "        else:\n",
    "            # LDA\n",
    "            covariance = model.covariance_\n",
    "        plot_ellipse(ax, model.means_[target], covariance, color)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are not doing great at separating stars from galaxies. What other information could help us distinguish these two? Here is where the domain knowledge becomes important. Stars can be observed only when they are close enough, while galaxies that we observe and look like stars (point source like) are much further away. Redshift is a measure of distance and is one of the columns in our dataset. Lets see what happens if we include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_columns = ['u-g', 'g-r' , 'log_redshift' ]\n",
    "col_pairs = list(combinations(plot_columns, 2))\n",
    "n = len(col_pairs)\n",
    "fig, axes = plt.subplots(nrows=n, figsize=(12, 7 * n))\n",
    "\n",
    "data_sample = data_train.sample(frac=.1)\n",
    "for ax, columns in zip(axes, col_pairs):\n",
    "    scatter_stars(ax, data_sample, columns, class_idx2name, class_colors, alpha=.3)\n",
    "    \n",
    "fig.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "Go back and change a color to 'redshift' in the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['u-g', 'log_redshift']\n",
    "\n",
    "X_train = data_train.loc[:,predictors]\n",
    "y_train = data_train.loc[:,'response']\n",
    "X_test = data_test.loc[:,predictors]\n",
    "y_test = data_test.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(X_train, y_train)\n",
    "qda.fit(X_train, y_train)\n",
    "fitted_models = [lda, qda]\n",
    "titles = ['LDA','QDA']\n",
    "class_colors=['r', 'g', 'b']\n",
    "\n",
    "f, axes = plt.subplots(1,2, figsize = (16,7))\n",
    "data_sample = data_train.sample(frac=.05)\n",
    "\n",
    "for i, (model, ax, title) in enumerate(zip(fitted_models, axes, titles)):\n",
    "    scatter_stars(\n",
    "        ax, data_sample,\n",
    "        columns=predictors,\n",
    "        class_labels=class_idx2name, class_colors=class_colors, edgecolor='black', lw=.25, s=10)\n",
    "\n",
    "    overlay_decision_boundary(ax, model, colors=class_colors, desaturate=.3)\n",
    "    ax.set_title(title)\n",
    "    print(\"{}: accuracy on train={:.2%}, test={:.2%}\".format(\n",
    "        title, model.score(X_train, y_train), model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA now does much better but LDA doesn't, why do you think that is?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
